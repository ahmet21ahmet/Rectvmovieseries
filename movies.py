import requests
import os
from collections import defaultdict

# Sabit API yolunu ve temel domain formatÄ±nÄ± tanÄ±mlÄ±yoruz.
# DeÄŸiÅŸen kÄ±sÄ±m {domain_num} ile belirtilmiÅŸtir.
BASE_DOMAIN_FORMAT = "https://m.prectv{domain_num}.sbs"
API_PATH = "/api/movie/by/filtres/0/created/{page}/4F5A9C3D9A86FA54EACEDDD635185/c3c5bd17-e37b-4b94-a944-8a3688a30452"

def find_working_domain(start=45, end=100):
    """
    Belirtilen sayÄ± aralÄ±ÄŸÄ±nda Ã§alÄ±ÅŸan bir domain bulmaya Ã§alÄ±ÅŸÄ±r.
    Ã–rn: m.prectv45.sbs, m.prectv46.sbs, ...
    """
    print(f"ğŸ” Ã‡alÄ±ÅŸan domain aranÄ±yor ({start}-{end} aralÄ±ÄŸÄ±nda)...")
    for i in range(start, end + 1):
        domain = BASE_DOMAIN_FORMAT.format(domain_num=i)
        try:
            # Domainin Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± anlamak iÃ§in ana sayfasÄ±na bir istek atÄ±yoruz.
            # timeout=5, isteÄŸin 5 saniyeden uzun sÃ¼rmesi durumunda vazgeÃ§mesini saÄŸlar.
            response = requests.get(domain, timeout=5, headers={"user-agent": "okhttp/4.12.0"})
            # HTTP 200 OK durum kodu, sayfanÄ±n baÅŸarÄ±lÄ± bir ÅŸekilde yÃ¼klendiÄŸini gÃ¶sterir.
            if response.status_code == 200:
                print(f"âœ… Ã‡alÄ±ÅŸan domain bulundu: {domain}")
                return domain
        except requests.exceptions.RequestException as e:
            # BaÄŸlantÄ± hatasÄ±, zaman aÅŸÄ±mÄ± gibi durumlarda bir sonraki domaini dene.
            print(f"   - {domain} Ã§alÄ±ÅŸmÄ±yor. ({e.__class__.__name__})")
            continue
    print("âŒ Ã‡alÄ±ÅŸan bir domain bulunamadÄ±.")
    return None

def get_all_movies(working_domain):
    """
    Ã‡alÄ±ÅŸan domain Ã¼zerinden tÃ¼m filmleri sayfa sayfa Ã§eker.
    """
    all_movies = []
    page = 0

    while True:
        # Tam API URL'sini Ã§alÄ±ÅŸan domain ve sayfa numarasÄ± ile oluÅŸturuyoruz.
        url = working_domain + API_PATH.format(page=page)
        print(f"ğŸ“„ Sayfa {page} Ã§ekiliyor...")
        try:
            response = requests.get(url, headers={"user-agent": "okhttp/4.12.0"})

            if response.status_code != 200:
                print(f"   - Hata: Sunucudan HTTP {response.status_code} kodu alÄ±ndÄ±.")
                break

            data = response.json()
            # EÄŸer sunucudan boÅŸ bir liste gelirse, filmlerin sonuna gelmiÅŸiz demektir.
            if not data:
                print(f"âœ… TÃ¼m filmler alÄ±ndÄ±. Toplam sayfa: {page}")
                break

            all_movies.extend(data)
            page += 1
        except requests.exceptions.RequestException as e:
            print(f"   - Hata: Veri Ã§ekilirken bir baÄŸlantÄ± hatasÄ± oluÅŸtu: {e}")
            break
        except ValueError: # JSON Ã§Ã¶zme hatasÄ±
            print(f"   - Hata: Sunucudan gelen yanÄ±t JSON formatÄ±nda deÄŸil.")
            break

    return all_movies

def categorize_movies(movies):
    """
    Filmleri tÃ¼rlerine (genres) gÃ¶re kategorilere ayÄ±rÄ±r.
    """
    categorized_movies = defaultdict(list)
    for movie in movies:
        genres = movie.get("genres", [])
        if not genres:
            categorized_movies["DiÄŸer"].append(movie)
            continue
        for genre in genres:
            category = genre.get("title", "DiÄŸer")
            categorized_movies[category].append(movie)
    return categorized_movies

def extract_movie_links(movies, category):
    """
    Belirli bir kategorideki filmler iÃ§in M3U formatÄ±nda metin oluÅŸturur.
    """
    playlist_lines = [
        f'#EXTM3U',
        f'#Kategori: {category}',
        f'#Bu kategoride {category.lower()} tÃ¼rÃ¼ndeki filmler yer almaktadÄ±r.\n'
    ]

    for movie in movies:
        title = movie.get("title", "Bilinmeyen Film")
        logo = movie.get("image", "")
        movie_id = str(movie.get("id", ""))
        sources = movie.get("sources", [])
        year = movie.get("year", "Tarih Yok")
        group = category

        for source in sources:
            url = source.get("url")
            if url and url.endswith(".m3u8"):
                # URL'yi proxy formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz
                url = f"https://1.nejyoner19.workers.dev/?url={url}"
                quality = source.get("quality", "")
                quality_str = f" [{quality}]" if quality else ""
                entry = [
                    f'#EXTINF:-1 tvg-id="{movie_id}" tvg-logo="{logo}" group-title="{group}",{title} ({year}){quality_str}',
                    '#EXTVLCOPT:http-user-agent=okhttp/4.12.0',
                    '#EXTVLCOPT:http-referrer=https://twitter.com',
                    url
                ]
                playlist_lines.extend(entry)
    return '\n'.join(playlist_lines)

def save_to_file(content, filename="rectv_filmler.m3u"):
    """
    OluÅŸturulan iÃ§eriÄŸi belirtilen dosyaya kaydeder.
    """
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"ğŸ“ M3U dosyasÄ± baÅŸarÄ±yla kaydedildi: {filename}")

if __name__ == "__main__":
    # 1. AdÄ±m: Ã‡alÄ±ÅŸan domaini bul (artÄ±k 45-100 aralÄ±ÄŸÄ±nda arayacak)
    domain = find_working_domain()

    # EÄŸer domain bulunamazsa betiÄŸi sonlandÄ±r
    if not domain:
        print("ğŸ”´ Ä°ÅŸlem durduruldu.")
    else:
        # 2. AdÄ±m: TÃ¼m filmleri Ã§ek
        movies = get_all_movies(domain)
        print(f"ğŸ¬ Toplam {len(movies)} film bulundu.")

        if movies:
            # 3. AdÄ±m: Filmleri kategorize et
            categorized_movies = categorize_movies(movies)
            
            # 4. AdÄ±m: TÃ¼m kategorileri tek bir dosyaya yazmak iÃ§in birleÅŸtir
            all_content_lines = []
            for category, movies_in_category in categorized_movies.items():
                m3u_content = extract_movie_links(movies_in_category, category)
                all_content_lines.append(m3u_content)
            
            # 5. AdÄ±m: Dosyaya kaydet
            final_content = "\n\n".join(all_content_lines)
            save_to_file(final_content)